{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-O25SbdcS6LD"
      },
      "outputs": [],
      "source": [
        "!pip install langchain langchain-community chromadb pypdf sentence-transformers openai -q\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# üìò BPCL Annual Report Chatbot using LangChain + OpenRouter\n",
        "# ============================================================\n",
        "\n",
        "\n",
        "#  Import Dependencies ---\n",
        "import os\n",
        "import warnings\n",
        "from google.colab import userdata\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_community.chat_models import ChatOpenAI\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.schema import Document\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "#  Set up the API Key ---\n",
        "try:\n",
        "    os.environ[\"OPENROUTER_API_KEY\"] = userdata.get(\"OPENROUTER_API_KEY\")\n",
        "except Exception as e:\n",
        "    print(\"‚ùå ERROR: Could not find the OPENROUTER_API_KEY secret.\")\n",
        "    print(\"Please add your OpenRouter API key to Colab's secrets (üîë icon on the left sidebar).\")\n",
        "    raise SystemExit(e)\n",
        "\n",
        "# Load and Process the PDF Document ---\n",
        "pdf_path = \"/content/bpcl-annual-report-2024-25.pdf\"\n",
        "\n",
        "if not os.path.exists(pdf_path):\n",
        "    print(f\"‚ùå ERROR: The file '{pdf_path}' was not found.\")\n",
        "    print(\"Please upload the 'bpcl-annual-report-2024-25.pdf' file to your Colab session.\")\n",
        "else:\n",
        "    print(\"üìÑ Loading and processing the BPCL Annual Report... please wait.\")\n",
        "\n",
        "    # Load the PDF pages\n",
        "    loader = PyPDFLoader(pdf_path)\n",
        "    pages = loader.load_and_split()\n",
        "\n",
        "    # Split the document into chunks for better embedding quality\n",
        "    pdf_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=800,\n",
        "        chunk_overlap=150,\n",
        "        length_function=len\n",
        "    )\n",
        "\n",
        "    docs = pdf_splitter.split_documents(pages)\n",
        "    documents = [Document(page_content=doc.page_content) for doc in docs]\n",
        "\n",
        "    #  Create Text Embeddings and Vector Store ---\n",
        "    print(\"‚öôÔ∏è Creating text embeddings and vector store...\")\n",
        "    embeddings = HuggingFaceEmbeddings(\n",
        "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "        model_kwargs={'device': 'cpu'}\n",
        "    )\n",
        "\n",
        "    vector_db = Chroma.from_documents(\n",
        "        documents,\n",
        "        embedding=embeddings\n",
        "    )\n",
        "\n",
        "    #  Set Up the Conversational AI Model ---\n",
        "    print(\"üß† Setting up the conversational AI model...\")\n",
        "    memory = ConversationBufferMemory(\n",
        "        memory_key=\"chat_history\",\n",
        "        return_messages=True\n",
        "    )\n",
        "\n",
        "    # Initialize OpenRouter-compatible ChatOpenAI model\n",
        "    llm = ChatOpenAI(\n",
        "        model_name=\"gpt-3.5-turbo\",\n",
        "        temperature=0.2,\n",
        "        openai_api_key=os.environ[\"OPENROUTER_API_KEY\"],\n",
        "        openai_api_base=\"https://openrouter.ai/api/v1\",\n",
        "        max_tokens=500\n",
        "    )\n",
        "\n",
        "    # Combine retriever + model + memory\n",
        "    qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "        llm=llm,\n",
        "        retriever=vector_db.as_retriever(),\n",
        "        memory=memory\n",
        "    )\n",
        "\n",
        "    print(\"\\n Setup complete! The chatbot is ready to use.\")\n",
        "    print(\"üí¨ Ask me anything about the *BPCL Annual Report 2024-25*.\")\n",
        "    print(\"Type 'Exit' anytime to end the chat.\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    # --- Step 7: Start the Chat Loop ---\n",
        "    while True:\n",
        "        try:\n",
        "            question = input(\"User: \")\n",
        "            if question.lower().strip() == \"exit\":\n",
        "                print(\"Bot: üëã Thank you for chatting. Goodbye!\")\n",
        "                break\n",
        "            if not question.strip():\n",
        "                continue\n",
        "\n",
        "            # Query the QA chain\n",
        "            answer = qa_chain({\"question\": question})\n",
        "            print(\"Bot:\", answer[\"answer\"])\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è An error occurred: {e}\")\n",
        "            break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pDss0PhTIdE",
        "outputId": "2174a1ca-1ad1-4e6e-9fdf-9745a2433192"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÑ Loading and processing the BPCL Annual Report... please wait.\n",
            "‚öôÔ∏è Creating text embeddings and vector store...\n",
            "üß† Setting up the conversational AI model...\n",
            "\n",
            " Setup complete! The chatbot is ready to use.\n",
            "üí¨ Ask me anything about the *BPCL Annual Report 2024-25*.\n",
            "Type 'Exit' anytime to end the chat.\n",
            "------------------------------------------------------------\n",
            "User: HI\n",
            "Bot: Hello! How can I assist you today?\n",
            "User: Can you tell me about BPCl\n",
            "Bot: BPCL, Bharat Petroleum Corporation Limited, is a prominent Oil and Gas company that serves both retail and bulk customers. It has an extensive network of retail outlets and LPG distributorships. The company has internal committees at its regions and refineries to ensure confidentiality in handling complaints. BPCL conducts Life Cycle Perspective/Assessments for its products, with details available in their Annual Report for investors. Additionally, BPCL has a Customer Care System for feedback and addresses complaints through the CPGRAMS portal. The company also focuses on responsible business conduct and sustainability issues related to environmental and social matters.\n",
            "User: What are the profits of the bpcl in 2024-2025\n",
            "Bot: BPCL reported a standalone net profit of ‚Çπ13,275.26 crore for the financial year 2024-25. Additionally, the consolidated net profit attributable to BPCL stood at ‚Çπ13,336.55 crore for the same period.\n",
            "User: exit\n",
            "Bot: üëã Thank you for chatting. Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hz5mMJuGTzZC"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}